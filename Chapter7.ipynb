{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-1\n",
    "!mkdir chap7\n",
    "%cd ./chap7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062b1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-3\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertJapaneseTokenizer, BertModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# 日本語の事前学習モデル\n",
    "MODEL_NAME = \"tohoku-nlp/bert-base-japanese-whole-word-masking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2a5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-4（説明コメント付き：BERTを用いたマルチラベル文分類の最小実装）\n",
    "# --------------------------------------------------------------------------------\n",
    "# 目的：\n",
    "#  - 事前学習済み BERT（エンコーダ本体：BertModel）の出力（最終層隠れ状態）から\n",
    "#    「[PAD] を除いたトークン平均（mean pooling）」で文ベクトルを作り、\n",
    "#    線形層でラベル数（num_labels）次元に写像して **マルチラベル**分類を行う。\n",
    "#\n",
    "# 理論メモ（マルチラベル vs マルチクラス）：\n",
    "#  - マルチクラス（排他的1クラス）では softmax + CrossEntropyLoss を用いるが、\n",
    "#  - マルチラベル（複数ラベル同時に1の可能性）では **各ラベルを独立なベルヌーイ**として扱い、\n",
    "#    出力は raw logits（活性前）→ **BCEWithLogitsLoss**（内部で sigmoid + BCE を数値安定に計算）を用いる。\n",
    "#  - 教師ラベルの形：shape [B, C]、各要素は {0,1}（float型推奨）。しきい値 0.5 などで陽性判定を後段で行う。\n",
    "#\n",
    "# プーリング設計（mean pooling の意図）：\n",
    "#  - [CLS] ベクトル単独の利用に比べ、文全体の情報を平均で取り入れやすい。短文～中程度の長さで堅実なベースライン。\n",
    "#  - attention_mask により [PAD] 位置は平均から除外（分母は非PADトークン数）。\n",
    "#  - 分母ゼロ（全PAD）対策：学習データ生成で通常発生しない想定だが、実務では clamp などで保険をかけると安全。\n",
    "#\n",
    "# そのほか設計の注意：\n",
    "#  - token_type_ids（= segment ids）は文対（sentence pair）で区別に使うが、単文では 0 固定でもよい。\n",
    "#  - 出力は慣例的には transformers の `SequenceClassifierOutput` を使うが、\n",
    "#    ここでは attributes にアクセスできる簡易オブジェクトを返す（互換性が必要なら差し替え推奨）。\n",
    "#  - クラス不均衡が強い場合は BCEWithLogitsLoss の `pos_weight` を利用すると勾配が安定する。\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class BertForSequenceClassificationMultiLabel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        # BertModel のロード（分類ヘッドなしの本体のみ）。\n",
    "        # - 入力：input_ids, attention_mask, token_type_ids\n",
    "        # - 出力：last_hidden_state（[B, L, H]）など\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "\n",
    "        # 文ベクトル（プーリング後の [B, H]）から各ラベルのロジット [B, C] を直線写像する層。\n",
    "        # - H: 隠れ次元（bert.config.hidden_size）、C: ラベル数（num_labels）\n",
    "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None\n",
    "    ):\n",
    "        # 1) BERT でトークン列を符号化し、最終層の隠れ状態を得る。\n",
    "        #    last_hidden_state の形は [B, L, H]（B:バッチ、L:系列長、H:隠れ次元）\n",
    "        bert_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        last_hidden_state = bert_output.last_hidden_state\n",
    "\n",
    "        # 2) [PAD] 以外の位置のみで平均プーリングして文ベクトルを作る。\n",
    "        #    - attention_mask は [B, L] の {0,1}。unsqueeze(-1) で [B, L, 1] に拡張し、\n",
    "        #      last_hidden_state（float）にマスク乗算→ PAD 位置を 0 化。\n",
    "        #    - 分母は非PADトークン数（attention_mask.sum(dim=1)）。\n",
    "        #      典型データでは 0 になることはないが、実運用では clamp_min(1e-9) などで安全策も検討。\n",
    "        averaged_hidden_state = (last_hidden_state * attention_mask.unsqueeze(-1)).sum(\n",
    "            1\n",
    "        ) / attention_mask.sum(1, keepdim=True)\n",
    "        # 参考（安全策の例、実装切替の際に利用）：\n",
    "        # denom = attention_mask.sum(1, keepdim=True).clamp_min(1e-9).float()\n",
    "        # masked = last_hidden_state * attention_mask.unsqueeze(-1).float()\n",
    "        # averaged_hidden_state = masked.sum(1) / denom\n",
    "\n",
    "        # 3) 線形層でラベル数 C 次元のロジットへ（活性はかけない：BCEWithLogitsLoss を使うため）\n",
    "        scores = self.linear(averaged_hidden_state)  # shape: [B, C]\n",
    "\n",
    "        # 4) 出力を dict 形式で用意（logits を必須、labels が来ていれば loss も計算）\n",
    "        output = {\"logits\": scores}\n",
    "\n",
    "        # 5) 教師ラベルが与えられた場合は損失を計算して返す。\n",
    "        #    - BCEWithLogitsLoss は内部で sigmoid を組み合わせた数値安定版。\n",
    "        #    - labels 形状は [B, C]、型は float（{0.0, 1.0}）を想定。\n",
    "        #    - クラス不均衡が強ければ pos_weight（shape [C]）の指定を検討。\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.BCEWithLogitsLoss()(scores, labels.float())\n",
    "            output[\"loss\"] = loss\n",
    "\n",
    "        # 6) 呼び出し側が `output.logits` / `output.loss` で参照できるよう簡易オブジェクト化。\n",
    "        #    transformers の標準 `SequenceClassifierOutput` を使う場合は差し替え可。\n",
    "        output = type(\"bert_output\", (object,), output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11ff6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using device = mps\n"
     ]
    }
   ],
   "source": [
    "# 7-5（説明コメント付き：マルチラベル文分類モデルのロードとデバイス配置）\n",
    "# -----------------------------------------------------------------------------\n",
    "# 目的：\n",
    "#  - 日本語BERTと同一語彙のトークナイザをロードし、\n",
    "#  - 7-4で定義した「BertForSequenceClassificationMultiLabel」を初期化、\n",
    "#  - 環境に応じた最適デバイス（MPS/CUDA/CPU）へ安全に配置する。\n",
    "#\n",
    "# 理論メモ：\n",
    "#  - 本モデルは出力が各ラベルの「ロジット」（活性前）で、マルチラベル想定（独立ベルヌーイ）。\n",
    "#    学習時は BCEWithLogitsLoss（sigmoid + BCE の安定版）を用いる。\n",
    "#  - num_labels=2 の場合、2つのラベルそれぞれを {0,1} で同時に予測する（softmaxではない）。\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "from transformers import BertJapaneseTokenizer\n",
    "\n",
    "# --- MODEL_NAME が未定義でも動くように保険を入れる ---\n",
    "try:\n",
    "    MODEL_NAME\n",
    "except NameError:\n",
    "    MODEL_NAME = (\n",
    "        \"tohoku-nlp/bert-base-japanese-whole-word-masking\"  # 東北大版日本語BERT（WWM）\n",
    "    )\n",
    "\n",
    "\n",
    "# --- デバイス選択：Mac(MPS) → CUDA → CPU の順で自動選択 ---\n",
    "def get_best_device() -> torch.device:\n",
    "    # Apple Silicon + macOS Metal\n",
    "    if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        return torch.device(\"mps\")\n",
    "    # NVIDIA GPU（Linux/Windowsなど）\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # フォールバック：CPU\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "device = get_best_device()\n",
    "print(f\"[info] using device = {device}\")\n",
    "\n",
    "# --- トークナイザのロード（モデルと同じ語彙でないとIDがずれて壊れる） ---\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# --- マルチラベル分類モデルの構築 ---\n",
    "# num_labels=2：2つのラベルを独立に予測（例：{スポーツ, IT} の属否を同時に判定 など）\n",
    "bert_scml = BertForSequenceClassificationMultiLabel(MODEL_NAME, num_labels=2)\n",
    "\n",
    "# --- 最適デバイスへ配置（.cuda()固定はMacで失敗するため .to(device) を統一使用） ---\n",
    "bert_scml = bert_scml.to(device)\n",
    "\n",
    "# 推論時は Dropout を止めたいので eval()、学習開始時は train() を呼ぶ。\n",
    "# bert_scml.eval()   # 例：推論前\n",
    "# bert_scml.train()  # 例：学習ループ開始時\n",
    "\n",
    "# （参考）出力の扱い：\n",
    "# - forward は {'logits': Tensor[B, C], 'loss': Tensor[]} 相当を返す簡易オブジェクト。\n",
    "# - 学習時は labels=[B, C] を与えると BCEWithLogitsLoss を内部計算し output.loss に入る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037ea7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# scores (logits): tensor([[0.2937, 0.1129],\n",
      "        [0.2349, 0.0266]], device='mps:0')\n",
      "# probs (sigmoid): tensor([[0.5729, 0.5282],\n",
      "        [0.5585, 0.5066]], device='mps:0')\n",
      "# predicted labels: tensor([[1, 1],\n",
      "        [1, 1]], device='mps:0')\n",
      "# subset accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# 7-6（説明コメント付き：マルチラベル推論・しきい値判定・サブセット精度）\n",
    "import torch\n",
    "\n",
    "# 入力テキスト：各サンプルに複数ラベルが立ち得る（マルチラベル）\n",
    "text_list = [\"今日の仕事はうまくいったが、体調があまり良くない。\", \"昨日は楽しかった。\"]\n",
    "\n",
    "# 教師ラベル（shape=[B, C]）：\n",
    "#  - マルチラベルなので各列（ラベル）を独立に {0,1} で表す\n",
    "#  - 例：C=2 のとき [仕事/体調] のような2軸を同時に予測するイメージ\n",
    "labels_list = [[1, 1], [0, 1]]\n",
    "\n",
    "# --- デバイス整合：モデル(bert_scml)の実デバイスに入力を合わせる ---\n",
    "device = next(bert_scml.parameters()).device\n",
    "\n",
    "# データの符号化\n",
    "#  - padding='longest' はバッチ内の最長系列に合わせて動的にPADを付与\n",
    "#  - 実運用では max_length+truncation=True+padding='max_length' で固定長化すると計算が安定\n",
    "encoding = tokenizer(text_list, padding=\"longest\", return_tensors=\"pt\")\n",
    "encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "\n",
    "# 教師ラベルテンソル\n",
    "#  - 学習で BCEWithLogitsLoss を使う場合は float（{0.0,1.0}）が望ましい\n",
    "#  - ここでは評価用に int 版も用意（比較演算時に便利）\n",
    "labels_float = torch.tensor(labels_list, dtype=torch.float32, device=device)\n",
    "labels_int = labels_float.to(torch.int64)\n",
    "\n",
    "# --- 推論：本モデルは logits（活性前スコア）を返す ---\n",
    "with torch.no_grad():\n",
    "    output = bert_scml(**encoding)\n",
    "scores = output.logits  # shape: [B, C]，各ラベルのロジット\n",
    "\n",
    "# --- 判定（しきい値） ---\n",
    "# 方式A：確率で判定（推奨。しきい値を柔軟に最適化できる）\n",
    "probs = scores.sigmoid()  # p(y_c=1|x)\n",
    "threshold = 0.5  # 必要に応じて ROC/PR で最適化\n",
    "labels_predicted = (probs >= threshold).to(torch.int64)\n",
    "\n",
    "# 方式B：ロジットの符号で判定（sigmoid≥0.5 と等価だが明示性に欠ける）\n",
    "# labels_predicted = (scores > 0).to(torch.int64)\n",
    "\n",
    "# --- 精度計算（subset accuracy：全ラベル一致率） ---\n",
    "#  - サンプルごとに全てのラベルが正解しているかを判定し、その平均をとる厳しめの指標\n",
    "num_correct = (labels_predicted == labels_int).all(dim=-1).sum().item()\n",
    "accuracy = num_correct / labels_int.size(0)\n",
    "\n",
    "# 参考：他の評価指標（マルチラベルで一般的）\n",
    "#  - example-based F1（サンプル単位のF1を平均）\n",
    "#  - micro/macro-F1（ラベル軸で集計）\n",
    "#  - Hamming loss（ラベル単位の誤り率）\n",
    "# これらは torchmetrics（MultilabelF1Score 等）で容易に算出可能\n",
    "\n",
    "print(\"# scores (logits):\", scores)\n",
    "print(\"# probs (sigmoid):\", probs)\n",
    "print(\"# predicted labels:\", labels_predicted)\n",
    "print(\"# subset accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a26f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loss: 0.671375036239624\n"
     ]
    }
   ],
   "source": [
    "# 7-7（説明コメント付き：マルチラベル損失（BCEWithLogitsLoss）の計算）\n",
    "# -----------------------------------------------------------------------------\n",
    "# 目的：\n",
    "#  - トークナイズ結果にマルチラベル教師（[B, C]）を同梱し、モデルの forward で\n",
    "#    BCEWithLogitsLoss（sigmoid + BCE の数値安定版）を自動計算させて loss を得る。\n",
    "#\n",
    "# 理論メモ：\n",
    "#  - マルチラベルでは各クラスを独立なベルヌーイとみなし、出力はロジット（活性前）。\n",
    "#    教師は float 型の {0.0, 1.0} 行列（shape=[B, C]）。softmax は使わない。\n",
    "#  - BCEWithLogitsLoss は内部で sigmoid を合成するため、出力に sigmoid をかけずに\n",
    "#    生のロジットをそのまま渡すのが正しい。\n",
    "#  - クラス不均衡が強い場合は pos_weight（shape=[C]）を指定すると陽性側の損失寄与を補正できる。\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "\n",
    "# --- デバイス整合：モデル(bert_scml)の実デバイスに入力を合わせる ---\n",
    "device = next(bert_scml.parameters()).device\n",
    "\n",
    "# --- データの符号化（バッチ内の最長に合わせて動的PAD） ---\n",
    "# 実運用では max_length+truncation=True+padding=\"max_length\" で固定長化すると計算が安定。\n",
    "encoding = tokenizer(text_list, padding=\"longest\", return_tensors=\"pt\")\n",
    "encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "\n",
    "# --- ラベルを同梱（[B, C]、float 型） ---\n",
    "# BCEWithLogitsLoss は float を前提。int のままでも内部で float 化されるが明示が安全。\n",
    "labels = torch.tensor(labels_list, dtype=torch.float32, device=device)\n",
    "encoding[\"labels\"] = labels\n",
    "\n",
    "# --- 損失の計算 ---\n",
    "# 学習時は train() にして Dropout を有効、評価時は eval() + no_grad()。\n",
    "bert_scml.train()  # 例：学習フェーズを想定（評価なら bert_scml.eval() と no_grad() を併用）\n",
    "output = bert_scml(**encoding)\n",
    "loss = output.loss  # BCEWithLogitsLoss（バッチ平均）\n",
    "\n",
    "print(\"# loss:\", float(loss.detach().cpu()))\n",
    "\n",
    "# （参考）不均衡対策：pos_weight を使う例（実装差し替え時）\n",
    "#   C = labels.size(1)\n",
    "#   pos_weight = torch.tensor([...], dtype=torch.float32, device=device)  # shape=[C]\n",
    "#   criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#   loss = criterion(output.logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d5d562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence_id': 0, 'sentence': '当期におけるわが国経済は、景気は緩やかな回復基調が続き、設備投資の持ち直し等を背景に企業収益は改善しているものの、海外では、資源国等を中心に不透明な状況が続き、為替が急激に変動するなど、依然として先行きが見通せない状況で推移した', 'opinions': [{'target': 'わが国経済', 'category': 'OOD#general', 'polarity': 'neutral', 'from': 6, 'to': 11}, {'target': '景気', 'category': 'OOD#general', 'polarity': 'positive', 'from': 13, 'to': 15}, {'target': '設備投資', 'category': 'OOD#general', 'polarity': 'positive', 'from': 28, 'to': 32}, {'target': '企業収益', 'category': 'OOD#general', 'polarity': 'positive', 'from': 42, 'to': 46}, {'target': '資源国等', 'category': 'OOD#general', 'polarity': 'neutral', 'from': 62, 'to': 66}, {'target': '為替', 'category': 'OOD#general', 'polarity': 'negative', 'from': 80, 'to': 82}]}\n"
     ]
    }
   ],
   "source": [
    "# 7-9\n",
    "data = json.load(open(\"chABSA-dataset/e00030_ann.json\"))\n",
    "print(data[\"sentences\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c030f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 6119\n",
      "# positives per class: {'neutral': 230, 'positive': 2210, 'negative': 1746}\n",
      "# example: {'text': '当連結会計年度におけるわが国経済は、政府の経済政策や日銀の金融緩和策により、企業業績、雇用・所得環境は改善し、景気も緩やかな回復基調のうちに推移いたしましたが、中国をはじめとするアジア新興国経済の減速懸念や、英国の欧州連合（ＥＵ）離脱決定、米国新政権への移行など、引き続き先行きは不透明な状況となっております', 'labels': [0, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 7-10（説明コメント付き：chABSA からマルチラベル（negative/neutral/positive）データセットを構築）\n",
    "# --------------------------------------------------------------------------------\n",
    "# 目的：\n",
    "#  - chABSA の JSON 群（各ファイルに sentences が入っている）から、\n",
    "#    文テキストと極性ラベル（3値：negative/neutral/positive）を **マルチラベル** 形式で取り出す。\n",
    "#    * ABSA は 1 文中に複数の「意見（aspect-opinion）」が存在し得るため、\n",
    "#      文レベルでは negative/neutral/positive が**同時に立つ**可能性を想定（= マルチラベル）。\n",
    "#\n",
    "# 理論メモ：\n",
    "#  - ここで作る labels は長さ 3 の one-hot ではなく **multi-hot**（例： [1,0,1]）。\n",
    "#    後段の学習では BCEWithLogitsLoss（独立ベルヌーイ）を用いるのが標準。\n",
    "#  - マルチクラス（排他的 1 ラベル）で扱いたい場合は、「優先順位ルール」や\n",
    "#    「確率最大クラスを1つ選ぶ」などの単一化手続きを別途設ける。\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# 極性 → ラベルID の対応（ID順は学習・評価で再利用するため**固定**しておく）\n",
    "category_id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id_to_category = {v: k for k, v in category_id.items()}  # デバッグ・可視化用の逆引き\n",
    "\n",
    "dataset = []  # 出力：[{ 'text': <str>, 'labels': [neg, neu, pos] }, ...] の配列\n",
    "\n",
    "# chABSA の JSON を列挙（ソートしておくと再現性が増す）\n",
    "for file in sorted(glob.glob(\"chABSA-dataset/*.json\")):\n",
    "    # JSON をロード（UTF-8 を想定）\n",
    "    with open(file, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 各ファイルは {\"sentences\": [...]} の構造を想定\n",
    "    # sentence 例：\n",
    "    #   {\n",
    "    #     \"sentence\": \"・・・\",\n",
    "    #     \"opinions\": [\n",
    "    #        {\"polarity\": \"positive\", ...},\n",
    "    #        {\"polarity\": \"negative\", ...},\n",
    "    #        ...\n",
    "    #     ]\n",
    "    #   }\n",
    "    for sentence in data.get(\"sentences\", []):\n",
    "        text = sentence.get(\"sentence\", \"\")\n",
    "\n",
    "        # 文レベルのマルチラベルベクトル（[neg, neu, pos]）\n",
    "        # - 同一文に複数 opinion がある場合、それぞれの極性に 1 を立てる（重複は 1 のまま）\n",
    "        labels = [0, 0, 0]\n",
    "        for opinion in sentence.get(\"opinions\", []):\n",
    "            pol = opinion.get(\"polarity\")\n",
    "            if pol in category_id:\n",
    "                labels[category_id[pol]] = 1\n",
    "            else:\n",
    "                # 未知の極性が来た場合の保険（データ品質に依存）\n",
    "                # 実務ではログ出力・スキップ数カウント等の監視を入れるとよい\n",
    "                pass\n",
    "\n",
    "        # 1 サンプル（テキスト + マルチラベル）を追加\n",
    "        sample = {\"text\": text, \"labels\": labels}\n",
    "        dataset.append(sample)\n",
    "\n",
    "# ------------------（任意）簡易サニティチェックと統計------------------\n",
    "# ラベル出現数（クラス別の陽性総数）を集計してみる\n",
    "label_totals = Counter()\n",
    "for s in dataset:\n",
    "    for i, bit in enumerate(s[\"labels\"]):\n",
    "        if bit:\n",
    "            label_totals[id_to_category[i]] += 1\n",
    "\n",
    "print(f\"# samples: {len(dataset)}\")\n",
    "print(\"# positives per class:\", dict(label_totals))\n",
    "print(\"# example:\", dataset[0] if dataset else None)\n",
    "\n",
    "# ここで得られた `dataset` は、後段の符号化フェーズで\n",
    "# tokenizer(text, ...) → input_ids/attention_mask/... を作り、\n",
    "# labels を torch.tensor([B, 3]) の float 型（{0.0,1.0}）にして BCEWithLogitsLoss へ渡す想定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2270d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '当連結会計年度におけるわが国経済は、政府の経済政策や日銀の金融緩和策により、企業業績、雇用・所得環境は改善し、景気も緩やかな回復基調のうちに推移いたしましたが、中国をはじめとするアジア新興国経済の減速懸念や、英国の欧州連合（ＥＵ）離脱決定、米国新政権への移行など、引き続き先行きは不透明な状況となっております', 'labels': [0, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 7-11\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94a365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
